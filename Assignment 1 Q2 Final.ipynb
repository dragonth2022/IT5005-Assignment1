{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group Name: AG 13.\n",
    "\n",
    "Student Name (Student ID):\n",
    "\n",
    "1. Zhao Yufan (A0255971U)\n",
    "\n",
    "2. Nayanthara Prathap Menon (A0261939R)\n",
    "\n",
    "3. Valeriy Ivanov (A0228607B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZOz6Y_cLGOT"
   },
   "source": [
    "# Question 2\n",
    "\n",
    "## Introduction to question 2\n",
    "\n",
    "In the second question of this assignment, we will explore the use of local search in genome assembly.\n",
    "\n",
    "We will use local search to assemble (construct) a large part of the nucleotide sequence of the monkeypox virus, which has been downloaded from the National Center for Biotechnology Information in the United States. Please note that no additional or specialized knowledge of biology or bioinformatics is required for this assignment. (Actually, the technical specifics of bioinformatics have been adapted and simplified for the purposes of this computer science assignment, so if you are a biologist, please do not apply preexisting knowledge to solve the problem. Furthermore, you should not attempt to search up the genome on genomic databases to \"guess\" the actual sequence, since we are more interested in your coding methodology rather than your attempts at reproducing a known sequence.)\n",
    "\n",
    "This is an introductory computer science assignment and not a bioinformatics assignment; we are simply using bioinformatics as a use case to illustrate the applicability of local search to the natural sciences. Therefore, no knowledge of bioinformatics is assumed or required. In the paragraphs that follow, I will give a short crash course which will cover all the domain knowledge you will need to know in order to tackle this problem.  \n",
    "\n",
    "For technical reasons, when we analyze the nucleotide sequence (genome) of a virus, we usually cannot “read” it in one fell swoop. We have to read the genome in parts, because the genome is usually too long for the machine to read in a single sitting. To simplify things, a “read” is a single view of part of the genome; think of it as a SUBSTRING, a partial view of the whole genome. After we have generated multiple reads of a genome, we then have to “stitch”, or combine, the different reads of the genome together. This process of stitching up reads of a genome into the final sequence is known as genome assembly. However, the different reads of the genome cannot just be concatenated like usual string concatenation. It’s not a situation where you have one read, “Hello”, and another read, “World”, and all you need to do is concatenate both strings together to make “Hello World”. Among other reasons, there are two major reasons why you can’t do so:\n",
    "\n",
    "1. You do not know which read came first. The reads are not ordered. How do you know “Hello” came after “World”? The answer is that you don’t. Imagine how complicated this situation might be if you had more than two reads. (This is indeed our situation, where we have $n$ reads, and $n>>2$.)\n",
    "\n",
    "2. One read may contain a substring contained in another read. Specifically, without loss of generality, part of the ending $x$ characters of a read (i.e., suffix) might also be found in the starting $x$ positions (i.e., prefix) of another read.\n",
    "\n",
    "- A computer scientist usually creates opportunities from problems. While this may be a “problem” in that you just can’t concatenate two strings blindly, the fact that strings contain shared “substrings” is actually a very helpful clue that you can use to “join” strings together. \n",
    "\n",
    "- Note that the choice of the value of $x$ could be a hyperparameter decided by the computer scientist.\n",
    "\n",
    "## Your tasks\n",
    "\n",
    "In this part of the assignment, you will work with (simulated) reads that I have generated from the nucleotide sequence of the monkeypox virus. In reality, bioinformatics is far more complicated, but here we will work with a simplified situation. Your task is to examine the reads that I have provided for you, and from there “infer” the nucleotide sequence that might have produced those reads. \n",
    "\n",
    "The reads are provided in the csv file `data.csv` which simply provides a list of unique strings. Note that you should NOT assume any particular ordering of the strings in this dataframe. In fact, the strings have already been shuffled randomly. \n",
    "\n",
    "NOTE: You are not allowed to use `pandas` or any other libraries apart from the Python STL to load the csv file.\n",
    "\n",
    "### Task A (3 marks): \n",
    "\n",
    "Create a directed graph. The nodes in the graph are the strings in the list of reads. An edge should be drawn FROM read A TO read B if and only if a suffix (of length $x$) of read A is also a prefix (obviously, also of length $x$) of read B. For the purposes of the assignment, limit the value of $x$ to between 5 and 30, both inclusive. That is, to be clear, $5\\leq x\\leq 30$. The weight of an edge between read A and read B should be the NEGATED value of $x$, i.e. $-x$. \n",
    "\n",
    "In your Jupyter notebook, please report the number of edges in your graph. Provide a barplot or histogram which shows the number of edges with different weights or weight categories. In this task, you are free to use plotting libraries such as `matplotlib` or `seaborn` to plot this graph.\n",
    "\n",
    "As an example, if read A is \"TACTAGT\" and read B is \"TAGTCCCCT\", then an edge is drawn FROM read A TO read B (i.e., $A \\rightarrow B$) with weight of $-4$. This is because the 4-suffix \"TAGT\" is also the 4-prefix of read B; in other words, the last 4 characters of read A (a substring of length 4) overlap with the first 4 characters of read B (a substring of length 4).\n",
    "\n",
    "### Task B (7 marks): \n",
    "\n",
    "From Task A, you now have a graph which shows connections between reads based on how they overlap, in theory you could draw a path through the graph and thereby derive the full sequence (genome).\n",
    "\n",
    "Task B asks you to use local search method(s) to determine a path through this directed graph of strings. \n",
    "\n",
    "- You are expected to use simulated annealing and tune the relevant configuration settings and hyperparameters. The minimum requirement is to implement simulated annealing.\n",
    "\n",
    "- Explain tha rationale behind the choice of scheduling strategy and parameters.\n",
    "\n",
    "- However, you may also explore other search methods in addition to simulated annealing. Marks will be awarded for effort.\n",
    "\n",
    "Note the following constraints:\n",
    "\n",
    "1. The path has to go through each and every vertex exactly once. For computer scientists, this constraint is reminiscent of the \"Traveling Salesman's Problem\", except that unlike TSP, we should not need to go back to the starting vertex again. \n",
    "\n",
    "2. For the purposes of neighbor generation / action selection at each node, bear in mind that a path through the graph which minimizes the total number of nucleotides in the assembled sequence is the preferred path. To state that another way, the assembled sequence should be derived from a path that goes through EACH and EVERY vertex exactly once, however we want this assembled sequence to be AS SHORT AS POSSIBLE.\n",
    "\n",
    "3. You are not given the starting (source/origin) or ending (destination) vertex.\n",
    "\n",
    "4. For avoidance of ambiguity, no cycles are allowed. You must not visit a vertex more than once.\n",
    "\n",
    "5. You are not allowed to use any libraries apart from the Python Standard Library.\n",
    "No import statements which import libraries outside of the Python STL should be found within your answer for Task B.\n",
    "\n",
    "Please remember to report the assembled sequence that you obtain. Although it would be great if you can come up with a good sequence, please feel reassured that we are more interested in your APPROACH to the problem, and so you can potentially get a reasonable score on this task even if your solution is \"wrong\". It is the process, rather than the result, which matters more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Task A}$:\n",
    "\n",
    "1. We have a biological virus with a really really long DNA, that is too long to read from beginning to end.\n",
    "2. We have read short portions of it multiple times, and we hope to piece them together.\n",
    "3. The short reads are given in the data.csv file.\n",
    "4. Suppose we have 2 reads X and Y. If the characters towards the end of read X matches those at the beginning of read Y, there is a good chance that the X and Y were together in the original DNA.\n",
    "\n",
    "$\\textbf{Toy Example}$:\n",
    "rawData2 =  [['0' , 'read_0' , 'TCGATCTG'] , ['1' , 'read_1' , 'TCTGA'] , ['2' , 'read_2' , 'TGAGA'] , ['3' , 'read_3' , 'ATCGA']]\n",
    "\n",
    "A possible DNA would be ATCGATCTGAGA, where we joined (read_3) - (read_0) - (read_1) - (read_2) , because there is substantial overlap between each read. The bigger the overlap, the better.\n",
    "\n",
    "$\\textbf{What we need to do for this question}$:\n",
    "\n",
    "Repeat the toy example, but for rawData = data.csv\n",
    "\n",
    "I have written some helper functions that I think will be useful:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{SufPreCompare(string1 = '' , string2 = '')}$ does the following:\n",
    "    Given 2 strings string1 and string2, returns a tuple (a,b), where:\n",
    "        a is the length of overlap of suffix of string 1 and prefix of string 2\n",
    "        b is the length of overlap of suffix of string 2 and prefix of string 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SufPreCompare(string1 = '' , string2 = ''):\n",
    "    \n",
    "    def StrCompare(string1, string2):\n",
    "        maxindex = min(len(string1) , len(string2),30)\n",
    "\n",
    "            \n",
    "        counter = maxindex\n",
    "        \n",
    "        while counter > 0:\n",
    "            \n",
    "            str1 = string1[len(string1) - counter : ]\n",
    "            str2 = string2[0 : counter]\n",
    "            \n",
    "            if str1 == str2:\n",
    "                return counter\n",
    "            else:\n",
    "                counter = counter - 1\n",
    "        return counter\n",
    "    \n",
    "    a = StrCompare(string1, string2)\n",
    "    b = StrCompare(string2, string1)\n",
    "    return (a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SufPreCompare(string1 = 'TCGATCTG' , string2 = 'TCTGA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation: The last 4 letters of string1 matches the first 4 letters of string2. The last 0 letters of string2 matches the first 0 letters of string1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SufPreCompare(string1 = 'TCGATCTG' , string2 = 'TCTGATCGAT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation: The last 4 letters of string1 matches the first 4 letters of string2. The last 5 letters of string2 matches the first 5 letters of string1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{read_line_by_lineRaw(filename = '')}$ does the following:\n",
    "    Open up a file stored in your computed called (filename), and returns its contents as a list. It is intended to be used on data.csv\n",
    "    \n",
    "The last line rawData.pop(0) removes the header. The output is the row that was removed from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read_line_by_lineRaw takes a csv file and returns its rows as a list    \n",
    "def read_line_by_lineRaw(filename = ''):\n",
    "    output = []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            b = line.rstrip('\\n')\n",
    "            a = b.split(',')\n",
    "            output.append(a)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{You need to upload the data.csv file to the jupyter notebook environment for the next cell to work:}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'read_index', 'read_sequence']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rawData is a list of reads, with each row being:\n",
    "#   ['row_count' , 'read_count' , 'read_string']\n",
    "rawData = read_line_by_lineRaw('data.csv')\n",
    "\n",
    "#remove the header row\n",
    "rawData.pop(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " There is a possibility that a particular read X gives a substring of another read Y\n",
    " We eliminate this possibility by doing the following:\n",
    "    \n",
    "1. Compare every possible pair of reads.\n",
    "2. If one of them is a substring of the other, change read to 'x'.\n",
    "3. Write a file ProcessedData.txt with 'x' reads intact.\n",
    "4. Write another file ProcessedData2.txt  with 'x' reads removed.\n",
    "    \n",
    "After manually comparing the number of lines in ProcessedData.txt and ProcessedData2.txt, we realise that\n",
    "None of the reads are sub-reads of another read.\n",
    "So we can use rawData as it is. The code below does the above.\n",
    "Since this is a one-time check, the manual check above is fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(rawData)):\n",
    "    for j in [x for x in range(len(rawData)) if x != i]:\n",
    "        if rawData[i][2] in rawData[j][2]:\n",
    "            rawData[i] = [rawData[i][0] , rawData[i][1] , 'x']\n",
    "\n",
    "with open('ProcessedData.txt' , 'w') as g:\n",
    "    for i in range(len(rawData)):\n",
    "        if rawData[2] != 'x':\n",
    "            g.write(f'{rawData[i][0]},{rawData[i][1]},{rawData[i][2]}\\n')\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "with open('ProcessedData2.txt' , 'w') as g:\n",
    "    for i in range(len(rawData)):\n",
    "        g.write(f'{rawData[i][0]},{rawData[i][1]},{rawData[i][2]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to produce a directed graph with the following as vertices and directed edge labels:\n",
    "1. Vertices are the reads\n",
    "2. Given 2 vertices A and B, the edge from A to B has edge label  -(length of overlap of end of A and beginning of B) \n",
    "\n",
    "$\\textbf{graphEdgeConstructor(m , n , dataset)}$ does the following: \n",
    "Given two reads m and n in a dataset (which should be the list returned by read_line_by_lineRaw(filename = ''), not the original file data.csv), returns a tuple of tuples ((m,n) , (x,y)), where:\n",
    "1. x is the overlap between the end of read m and beginning of read n\n",
    "2. y is the overlap between the end of read n and beginning of read m\n",
    "\n",
    "$\\textbf{contructEdges(dataset)}$ does the following:\n",
    "1. Scan through the entire dataset.\n",
    "2. For pairs of reads (m,n) with non-zero overlaps (x,y) as defined above in graphEdgeConstructor(m , n , dataset), put all of them into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphEdgeConstructor(m , n , dataset):\n",
    "    comparison = SufPreCompare(dataset[m][2] , dataset[n][2])\n",
    "    return ((m,n) , comparison)\n",
    "\n",
    "def constructEdges(dataset):\n",
    "    output = []\n",
    "    test4 = len(dataset)\n",
    "    for i in range(test4):\n",
    "        for j in range(i+1,test4):\n",
    "            temp = graphEdgeConstructor(i , j, dataset)\n",
    "            #if temp[1] != (0,0):\n",
    "            if temp[1][0] > 0 or temp[1][1] > 0:\n",
    "                output.append(temp)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test these functions on the Toy Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0, 1), (4, 0)),\n",
       " ((0, 2), (2, 0)),\n",
       " ((0, 3), (0, 4)),\n",
       " ((1, 2), (3, 0)),\n",
       " ((1, 3), (1, 0)),\n",
       " ((2, 3), (1, 0))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawData2 = [['0','read_0','TCGATCTG'],['1','read_1','TCTGA'],['2','read_2','TGAGA'],['3','read_3','ATCGA']]\n",
    "rawDataMini = rawData[0:300]\n",
    "#rawDataMini is the first 300 rows of data.csv in list format\n",
    "\n",
    "constructEdges(rawData2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Explanation}:$ We see that the biggest numbers that appear on the right column of tuple are 4, 4, and 3 in rows 0, 2, and 3. This suggests the following 'joining-up' of our DNA sequence:\n",
    "\n",
    "1. row 0: This means there are 4 overlapping letters at the end of read_0 and beginning of read_1\n",
    "2. row 2: This means there are 4 overlapping letters at the end of read_3 and beginning of read_0\n",
    "3. row 3: This means there are 3 overlapping letters at the end of read_1 and beginning of read_2\n",
    "\n",
    "This suggests our DNA should be (read_3) - (read_0) - (read_1) - (read_2). Hence:\n",
    "\n",
    "DNA = 'ATCGATCTGAGA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{constructEdges2(dataset)}$ does the samething as constructEdges(dataset), except that it only returns pairs where the overlap is from 5 to 30 characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructEdges2(dataset):\n",
    "    output = []\n",
    "    test4 = len(dataset)\n",
    "    for i in range(test4):\n",
    "        for j in range(i+1,test4):\n",
    "            temp = graphEdgeConstructor(i , j, dataset)\n",
    "            #if temp[1] != (0,0):\n",
    "            if (temp[1][0] > 4 or temp[1][1] > 4) and temp[1][0]<31 and temp[1][1]<31:\n",
    "                output.append(temp)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create a graph class, and our specific graph is dnaProblem. We use the adjacency matrix representation of a graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Graph:\n",
    "    def __init__(self, num_of_nodes, directed=True):\n",
    "        self.m_num_of_nodes = num_of_nodes\n",
    "        self.m_directed = directed\n",
    "\n",
    "        # Initialize the adjacency matrix\n",
    "        # Create a matrix with `num_of_nodes` rows and columns\n",
    "        self.m_adj_matrix = [[0 for column in range(num_of_nodes)] \n",
    "                            for row in range(num_of_nodes)]\n",
    "\n",
    "    def add_edge(self, node1, node2, weight=1):\n",
    "        self.m_adj_matrix[node1][node2] = weight\n",
    "\n",
    "        if not self.m_directed:\n",
    "            self.m_adj_matrix[node2][node1] = weight\n",
    "\n",
    "    def print_adj_matrix(self):\n",
    "        print(self.m_adj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = constructEdges2(rawData)\n",
    "    \n",
    "dnaProblem = Graph(599, directed = True)\n",
    "\n",
    "for i in range(len(edges)):\n",
    "    consider = edges[i]\n",
    "    dnaProblem.add_edge(consider[0][0] , consider[0][1] , weight = -consider[1][0])\n",
    "    dnaProblem.add_edge(consider[0][1] , consider[0][0] , weight = -consider[1][1])\n",
    "    \n",
    "for i in range(len(dnaProblem.m_adj_matrix)):\n",
    "    for j in range(len(dnaProblem.m_adj_matrix)):\n",
    "        if dnaProblem.m_adj_matrix[i][j] > -5:\n",
    "            dnaProblem.m_adj_matrix[i][j] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now plot a bar chart, with horizontal axis being weights and vertical axis being the number of edges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "weights = list(range(-30,-4))\n",
    "finalcounts = []\n",
    "\n",
    "for i in range(-30,-4):\n",
    "    count = 0\n",
    "    for j in range(599):\n",
    "        for k in range(599):\n",
    "            if dnaProblem.m_adj_matrix[j][k] == i:\n",
    "                count = count+1\n",
    "    finalcounts.append(count)\n",
    "    \n",
    "plt.bar(weights,finalcounts)\n",
    "plt.xlabel('weight')\n",
    "plt.ylabel('edge count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Task B}$：We now implement our task as a Travelling salesman problem, with the \"map graph\" being the adjacency matrix found above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "import random\n",
    "import numpy.random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSP:\n",
    "    def __init__(self , graph : Graph , initial : list):\n",
    "        \n",
    "        #self.state is the path we are taking through self.graph\n",
    "        self.graph = graph\n",
    "        self.state = initial\n",
    "        self.temp = initial\n",
    "\n",
    "    \n",
    "    def actions(self, state : list):\n",
    "        actions = ['Reverse' , 'Transport']\n",
    "        return actions\n",
    "    \n",
    "    \n",
    "    \n",
    "    def result(self, state : list, action):\n",
    "        \n",
    "        def listReverse(L , a , b):\n",
    "\n",
    "            beginning = L[0:a]\n",
    "            middle = L[a:b]\n",
    "            end = L[b:]\n",
    "            middle.reverse()\n",
    "            return beginning + middle + end\n",
    "        \n",
    "        def listTransport(L, a , b , c):\n",
    "\n",
    "            beginning = L[0:a]\n",
    "            middle = L[a:b]\n",
    "            end = L[b:]\n",
    "            intermediate = beginning + end\n",
    "            intS1 = intermediate[0:c]\n",
    "            intS2 = intermediate[c:]\n",
    "            return intS1 + middle + intS2\n",
    "        \n",
    "        if action == 'Reverse':\n",
    "            x = random.randint(0 , len(self.state))\n",
    "            y = random.randint(0 , len(self.state))\n",
    "            a = min(x,y)\n",
    "            b = max(x,y) + 1\n",
    "            return listReverse(self.state , a , b)\n",
    "        \n",
    "        if action == 'Transport':\n",
    "            x = random.randint(0 , len(self.state)-1)\n",
    "            y = random.randint(x , len(self.state))\n",
    "\n",
    "            c = random.randint(0 , len(self.state) - (y-x) + 1)\n",
    "            return listTransport(self.state , x , y , c)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def cost(self, path):\n",
    "        vertices = len(self.graph.m_adj_matrix)-1\n",
    "        maxvertex = 0\n",
    "        for i in path:\n",
    "            if i > maxvertex:\n",
    "                maxvertex = i\n",
    "                              \n",
    "        if maxvertex > vertices:\n",
    "            raise ValueError('Path tries to visit a vertex not in graph')\n",
    "        else:\n",
    "            path_cost = 0\n",
    "            positionInPath = path[0]\n",
    "            for i in path[1:]:\n",
    "                path_cost = path_cost + self.graph.m_adj_matrix[positionInPath][i]\n",
    "                positionInPath = i\n",
    "        return path_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the simulated annealing algorithm to solve the Travelling Salesman Problem. We first define a cooling schedule, then we implement the algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_schedule(k=10000, lam=0.005, limit=sys.maxsize):\n",
    "    \"\"\"One possible schedule function for simulated annealing\"\"\"\n",
    "    return lambda t: (k * math.exp(-lam * t) if t < limit else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 10000\n",
    "decay = 0.0005\n",
    "maxiterations = 100000\n",
    "def simulated_annealing(problem, schedule=exp_schedule(k = m , lam = decay , limit = maxiterations)):\n",
    "    \n",
    "    for t in range(50000):\n",
    "        T = schedule(t)\n",
    "        if T == 0:\n",
    "            return problem.state\n",
    "        action = random.choice(['Reverse' , 'Transport'])\n",
    "        problem.temp = problem.result(problem.state , action)\n",
    "        \n",
    "\n",
    "        delta_e = problem.cost(problem.state) - problem.cost(problem.temp)\n",
    "        if delta_e > 0 or numpy.random.binomial(1, (schedule(t)/ ((1.02)*m) ) ) == 1:\n",
    "            problem.state = problem.temp\n",
    "    return problem.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 358, 222, 243, 209, 108, 109, 110, 5, 327, 495, 208, 506, 174, 383, 382, 191, 432, 563, 564, 323, 284, 534, 527, 290, 291, 26, 34, 35, 333, 53, 365, 112, 171, 588, 153, 501, 419, 144, 567, 31, 30, 360, 37, 339, 353, 168, 351, 308, 573, 154, 372, 568, 177, 457, 577, 405, 273, 566, 420, 459, 384, 237, 350, 590, 507, 142, 401, 476, 475, 474, 316, 238, 597, 82, 155, 313, 366, 227, 363, 547, 472, 540, 276, 481, 557, 63, 299, 91, 489, 574, 575, 123, 551, 537, 431, 71, 558, 337, 571, 486, 95, 96, 97, 98, 274, 272, 100, 157, 74, 116, 460, 216, 92, 151, 585, 182, 38, 195, 517, 439, 22, 294, 295, 464, 417, 524, 511, 249, 440, 441, 498, 23, 232, 58, 598, 318, 21, 20, 166, 10, 9, 331, 416, 421, 252, 388, 315, 317, 247, 559, 560, 241, 179, 178, 296, 470, 407, 376, 239, 380, 152, 67, 163, 162, 161, 230, 390, 452, 309, 343, 594, 595, 494, 70, 596, 68, 403, 404, 463, 381, 28, 27, 584, 311, 119, 120, 214, 386, 332, 342, 310, 576, 146, 145, 189, 173, 565, 203, 322, 349, 586, 587, 433, 114, 234, 496, 88, 89, 90, 504, 503, 134, 135, 328, 268, 138, 32, 580, 122, 361, 521, 455, 73, 244, 591, 221, 45, 61, 188, 469, 398, 139, 102, 147, 156, 165, 125, 480, 184, 578, 326, 515, 418, 375, 373, 369, 368, 345, 254, 253, 593, 158, 212, 367, 548, 193, 194, 6, 301, 159, 519, 462, 65, 183, 39, 374, 49, 341, 354, 526, 535, 197, 447, 446, 445, 444, 443, 314, 260, 220, 289, 572, 62, 570, 83, 348, 285, 579, 266, 41, 42, 43, 493, 411, 410, 75, 24, 57, 233, 133, 127, 126, 523, 81, 200, 201, 281, 269, 219, 85, 130, 259, 500, 52, 338, 520, 479, 319, 377, 240, 213, 458, 224, 223, 33, 485, 228, 298, 44, 395, 394, 393, 392, 391, 2, 12, 434, 435, 196, 546, 467, 215, 553, 169, 286, 180, 414, 113, 312, 307, 306, 115, 205, 206, 181, 304, 303, 554, 54, 561, 292, 293, 175, 442, 497, 302, 176, 477, 242, 539, 538, 334, 40, 422, 271, 385, 541, 542, 121, 262, 261, 364, 562, 59, 46, 412, 362, 8, 229, 529, 528, 502, 202, 136, 399, 107, 106, 378, 324, 105, 258, 280, 288, 510, 509, 437, 533, 3, 4, 436, 118, 51, 508, 111, 137, 77, 217, 218, 468, 226, 406, 248, 14, 456, 522, 66, 428, 429, 430, 225, 246, 148, 143, 556, 555, 250, 251, 425, 424, 423, 427, 164, 488, 387, 518, 13, 499, 93, 461, 583, 150, 408, 94, 409, 192, 72, 140, 141, 87, 25, 283, 282, 204, 478, 265, 450, 449, 530, 531, 532, 592, 582, 471, 490, 415, 190, 514, 513, 236, 235, 198, 569, 128, 279, 581, 297, 451, 257, 256, 389, 149, 255, 29, 400, 454, 543, 117, 101, 277, 512, 211, 210, 525, 263, 16, 76, 371, 370, 379, 336, 549, 550, 402, 413, 321, 320, 325, 7, 231, 104, 103, 50, 36, 491, 275, 172, 453, 264, 18, 19, 207, 347, 346, 124, 11, 167, 359, 64, 131, 132, 473, 426, 84, 330, 340, 355, 99, 482, 483, 484, 199, 352, 335, 69, 438, 397, 396, 356, 305, 545, 544, 536, 505, 129, 17, 466, 465, 270, 448, 86, 245, 287, 170, 160, 15, 267, 589, 552, 329, 344, 492, 60, 48, 300, 487, 55, 56, 47, 357, 278, 78, 79, 80, 187, 186, 185, 516]\n"
     ]
    }
   ],
   "source": [
    "initialPath = list(range(599))\n",
    "dnaTSP = TSP(dnaProblem , initialPath)\n",
    "\n",
    "solution = simulated_annealing(dnaTSP, schedule=exp_schedule())\n",
    "print(solution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2630\n"
     ]
    }
   ],
   "source": [
    "print(dnaTSP.cost(solution))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm works as follows. We first initialise with a fixed path that transverse the graph from vertex 0 to 599 in order. We represent this path by a list $[0,1,2,...,598,599]$. We then define two moves: Reverse(a,b) and Transport(a,b,c). The moves do the following:\n",
    "\n",
    "1. Reverse(a,b) reverses the portion of the list between index a and b. More precisely, it takes the list $[0,1,2,...,598,599]$, slices it up into 3 portions $[0,1,2,...,a]$ , $[a+1, a+2, ..., b-1]$ , $[b, b+1,..., 598, 599]$, reverses the middle portion (so it becomes $[b-1, b-2, ..., a+2, a+1]$, and then concatenate them back together, forming the new list $[0,1,2,...,b-1,b-2,..., a+2, a+1, b, b+1, ..., 598, 599]$. \n",
    "\n",
    "2. Transport(a,b,c) moves a portion of the list between index a and b into a new position c. More precisely it takes the list $[0,1,2,...,598,599]$, slice it up into 3 portions, $[0,1,2,...,a]$ , $[a+1, a+2, ..., b-1]$ , $[b, b+1,..., 598, 599]$, concatenate the first and last portion into $[0,1,2,...,a ,b, b+1,..., 598, 599]$. It then selects an index c in this new list, and insert the middle portion $[a+1, a+2, ..., b-1]$ at this position. So the new list becomes $[0,1,...c,a+1,a+2,...,b-1, c+1, ...598,599]$.\n",
    "\n",
    "\n",
    "These 2 operations will generate all possible permutations of vertices that we transverse the path. In fact, the reverse operation alone is enough. (A result in group theory in mathematics says that the set of all transpositions generate the symmetric group on n elements). But this is too slow and some permutations may be unreachable in a reasonable number of iterations, so we allow for more flexibility ( by choosing $a$ and $b$ independently, and also introducing the 'Transport' move.)\n",
    "\n",
    "Starting with an initial path, a random move (either 'Reverse' or 'Transport') is chosen, and its parameters are again chosen randomly (with two restrictions: $a < b$ for both 'Reverse' and 'Transport' so that the slicing makes sense, and $c$ is a valid index for 'Transport'). The cost of transversing the new path is calculated. If the new cost is better than the original cost, the move is accepted. Otherwise, the move is accepted with probability $p$ as determined by the simulated annealing schedule.\n",
    "\n",
    "An exponential decay schedule was chosen because we don't want to be stuck on a small local maximum early on in the simulated annealing process. We also don't want to accept a destructive move after many iterations because we are likely near the global minimum at that point."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
