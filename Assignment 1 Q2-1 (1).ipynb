{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group Name: AG xx.\n",
    "\n",
    "Student Name (Student ID):\n",
    "\n",
    "1. Zhao Yufan (xxxxxxx)\n",
    "\n",
    "2. xxxx xxxxx (xxxxxxx)\n",
    "\n",
    "3. xxxx xxxxx (xxxxxxx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZOz6Y_cLGOT"
   },
   "source": [
    "# Question 2\n",
    "\n",
    "## Introduction to question 2\n",
    "\n",
    "In the second question of this assignment, we will explore the use of local search in genome assembly.\n",
    "\n",
    "We will use local search to assemble (construct) a large part of the nucleotide sequence of the monkeypox virus, which has been downloaded from the National Center for Biotechnology Information in the United States. Please note that no additional or specialized knowledge of biology or bioinformatics is required for this assignment. (Actually, the technical specifics of bioinformatics have been adapted and simplified for the purposes of this computer science assignment, so if you are a biologist, please do not apply preexisting knowledge to solve the problem. Furthermore, you should not attempt to search up the genome on genomic databases to \"guess\" the actual sequence, since we are more interested in your coding methodology rather than your attempts at reproducing a known sequence.)\n",
    "\n",
    "This is an introductory computer science assignment and not a bioinformatics assignment; we are simply using bioinformatics as a use case to illustrate the applicability of local search to the natural sciences. Therefore, no knowledge of bioinformatics is assumed or required. In the paragraphs that follow, I will give a short crash course which will cover all the domain knowledge you will need to know in order to tackle this problem.  \n",
    "\n",
    "For technical reasons, when we analyze the nucleotide sequence (genome) of a virus, we usually cannot “read” it in one fell swoop. We have to read the genome in parts, because the genome is usually too long for the machine to read in a single sitting. To simplify things, a “read” is a single view of part of the genome; think of it as a SUBSTRING, a partial view of the whole genome. After we have generated multiple reads of a genome, we then have to “stitch”, or combine, the different reads of the genome together. This process of stitching up reads of a genome into the final sequence is known as genome assembly. However, the different reads of the genome cannot just be concatenated like usual string concatenation. It’s not a situation where you have one read, “Hello”, and another read, “World”, and all you need to do is concatenate both strings together to make “Hello World”. Among other reasons, there are two major reasons why you can’t do so:\n",
    "\n",
    "1. You do not know which read came first. The reads are not ordered. How do you know “Hello” came after “World”? The answer is that you don’t. Imagine how complicated this situation might be if you had more than two reads. (This is indeed our situation, where we have $n$ reads, and $n>>2$.)\n",
    "\n",
    "2. One read may contain a substring contained in another read. Specifically, without loss of generality, part of the ending $x$ characters of a read (i.e., suffix) might also be found in the starting $x$ positions (i.e., prefix) of another read.\n",
    "\n",
    "- A computer scientist usually creates opportunities from problems. While this may be a “problem” in that you just can’t concatenate two strings blindly, the fact that strings contain shared “substrings” is actually a very helpful clue that you can use to “join” strings together. \n",
    "\n",
    "- Note that the choice of the value of $x$ could be a hyperparameter decided by the computer scientist.\n",
    "\n",
    "## Your tasks\n",
    "\n",
    "In this part of the assignment, you will work with (simulated) reads that I have generated from the nucleotide sequence of the monkeypox virus. In reality, bioinformatics is far more complicated, but here we will work with a simplified situation. Your task is to examine the reads that I have provided for you, and from there “infer” the nucleotide sequence that might have produced those reads. \n",
    "\n",
    "The reads are provided in the csv file `data.csv` which simply provides a list of unique strings. Note that you should NOT assume any particular ordering of the strings in this dataframe. In fact, the strings have already been shuffled randomly. \n",
    "\n",
    "NOTE: You are not allowed to use `pandas` or any other libraries apart from the Python STL to load the csv file.\n",
    "\n",
    "### Task A (3 marks): \n",
    "\n",
    "Create a directed graph. The nodes in the graph are the strings in the list of reads. An edge should be drawn FROM read A TO read B if and only if a suffix (of length $x$) of read A is also a prefix (obviously, also of length $x$) of read B. For the purposes of the assignment, limit the value of $x$ to between 5 and 30, both inclusive. That is, to be clear, $5\\leq x\\leq 30$. The weight of an edge between read A and read B should be the NEGATED value of $x$, i.e. $-x$. \n",
    "\n",
    "In your Jupyter notebook, please report the number of edges in your graph. Provide a barplot or histogram which shows the number of edges with different weights or weight categories. In this task, you are free to use plotting libraries such as `matplotlib` or `seaborn` to plot this graph.\n",
    "\n",
    "As an example, if read A is \"TACTAGT\" and read B is \"TAGTCCCCT\", then an edge is drawn FROM read A TO read B (i.e., $A \\rightarrow B$) with weight of $-4$. This is because the 4-suffix \"TAGT\" is also the 4-prefix of read B; in other words, the last 4 characters of read A (a substring of length 4) overlap with the first 4 characters of read B (a substring of length 4).\n",
    "\n",
    "### Task B (7 marks): \n",
    "\n",
    "From Task A, you now have a graph which shows connections between reads based on how they overlap, in theory you could draw a path through the graph and thereby derive the full sequence (genome).\n",
    "\n",
    "Task B asks you to use local search method(s) to determine a path through this directed graph of strings. \n",
    "\n",
    "- You are expected to use simulated annealing and tune the relevant configuration settings and hyperparameters. The minimum requirement is to implement simulated annealing.\n",
    "\n",
    "- Explain tha rationale behind the choice of scheduling strategy and parameters.\n",
    "\n",
    "- However, you may also explore other search methods in addition to simulated annealing. Marks will be awarded for effort.\n",
    "\n",
    "Note the following constraints:\n",
    "\n",
    "1. The path has to go through each and every vertex exactly once. For computer scientists, this constraint is reminiscent of the \"Traveling Salesman's Problem\", except that unlike TSP, we should not need to go back to the starting vertex again. \n",
    "\n",
    "2. For the purposes of neighbor generation / action selection at each node, bear in mind that a path through the graph which minimizes the total number of nucleotides in the assembled sequence is the preferred path. To state that another way, the assembled sequence should be derived from a path that goes through EACH and EVERY vertex exactly once, however we want this assembled sequence to be AS SHORT AS POSSIBLE.\n",
    "\n",
    "3. You are not given the starting (source/origin) or ending (destination) vertex.\n",
    "\n",
    "4. For avoidance of ambiguity, no cycles are allowed. You must not visit a vertex more than once.\n",
    "\n",
    "5. You are not allowed to use any libraries apart from the Python Standard Library.\n",
    "No import statements which import libraries outside of the Python STL should be found within your answer for Task B.\n",
    "\n",
    "Please remember to report the assembled sequence that you obtain. Although it would be great if you can come up with a good sequence, please feel reassured that we are more interested in your APPROACH to the problem, and so you can potentially get a reasonable score on this task even if your solution is \"wrong\". It is the process, rather than the result, which matters more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "oBnbZpd2bt1N"
   },
   "outputs": [],
   "source": [
    "# Problem Class\n",
    "class Problem:\n",
    "    \"\"\"The abstract class for a formal problem. A new domain subclasses this,\n",
    "    overriding `actions` and `results`, and perhaps other methods.\n",
    "    The default heuristic is 0 and the default action cost is 1 for all states.\n",
    "    When you create an instance of a subclass, specify `initial`, and `goal` states \n",
    "    (or give an `is_goal` method) and perhaps other keyword args for the subclass.\"\"\"\n",
    "\n",
    "    def __init__(self, initial=None, goal=None, **kwds): \n",
    "        self.__dict__.update(initial=initial, goal=goal, **kwds) \n",
    "        \n",
    "    def actions(self, state):        raise NotImplementedError\n",
    "    def result(self, state, action): raise NotImplementedError\n",
    "    def is_goal(self, state):        return state == self.goal\n",
    "    def action_cost(self, s, a, s1): return 1\n",
    "    def h(self, node):               return 0\n",
    "    \n",
    "    def __str__(self):\n",
    "        return '{}({!r}, {!r})'.format(\n",
    "            type(self).__name__, self.initial, self.goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the following Node class to generate search tree\n",
    "import math\n",
    "class Node:\n",
    "    \"A Node in a search tree.\"\n",
    "    def __init__(self, state, parent=None, action=None, path_cost=0):\n",
    "        self.__dict__.update(state=state, parent=parent, action=action, path_cost=path_cost)\n",
    "\n",
    "    def __repr__(self): return '<{}>'.format(self.state)\n",
    "    def __len__(self): return 0 if self.parent is None else (1 + len(self.parent))\n",
    "    def __lt__(self, other): return self.path_cost < other.path_cost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "B2-y3Nt9ccxj"
   },
   "outputs": [],
   "source": [
    "# Code to generate neighbours, value of states, etc.\n",
    "class TSP(Problem):\n",
    "    #Implement TSP class here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Task A}$:\n",
    "\n",
    "1. We have a biological virus with a really really long DNA, that is too long to read from beginning to end.\n",
    "2. We have read short portions of it multiple times, and we hope to piece them together.\n",
    "3. The short reads are given in the data.csv file.\n",
    "4. Suppose we have 2 reads X and Y. If the characters towards the end of read X matches those at the beginning of read Y, there is a good chance that the X and Y were together in the original DNA.\n",
    "\n",
    "$\\textbf{Toy Example}$:\n",
    "rawData2 =  [['0' , 'read_0' , 'TCGATCTG'] , ['1' , 'read_1' , 'TCTGA'] , ['2' , 'read_2' , 'TGAGA'] , ['3' , 'read_3' , 'ATCGA']]\n",
    "\n",
    "A possible DNA would be ATCGATCTGAGA, where we joined (read_3) - (read_0) - (read_1) - (read_2) , because there is substantial overlap between each read. The bigger the overlap, the better.\n",
    "\n",
    "$\\textbf{What we need to do for this question}$:\n",
    "\n",
    "Repeat the toy example, but for rawData = data.csv\n",
    "\n",
    "I have written some helper functions that I think will be useful:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{SufPreCompare(string1 = '' , string2 = '')}$ does the following:\n",
    "    Given 2 strings string1 and string2, returns a tuple (a,b), where:\n",
    "        a is the length of overlap of suffix of string 1 and prefix of string 2\n",
    "        b is the length of overlap of suffix of string 2 and prefix of string 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SufPreCompare(string1 = '' , string2 = ''):\n",
    "    \n",
    "    def StrCompare(string1, string2):\n",
    "        maxindex = min(len(string1) , len(string2),30)\n",
    "\n",
    "            \n",
    "        counter = maxindex\n",
    "        \n",
    "        while counter > 0:\n",
    "            \n",
    "            str1 = string1[len(string1) - counter : ]\n",
    "            str2 = string2[0 : counter]\n",
    "            \n",
    "            if str1 == str2:\n",
    "                return counter\n",
    "            else:\n",
    "                counter = counter - 1\n",
    "        return counter\n",
    "    \n",
    "    a = StrCompare(string1, string2)\n",
    "    b = StrCompare(string2, string1)\n",
    "    return (a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SufPreCompare(string1 = 'TCGATCTG' , string2 = 'TCTGA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation: The last 4 letters of string1 matches the first 4 letters of string2. The last 0 letters of string2 matches the first 0 letters of string1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SufPreCompare(string1 = 'TCGATCTG' , string2 = 'TCTGATCGAT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation: The last 4 letters of string1 matches the first 4 letters of string2. The last 5 letters of string2 matches the first 5 letters of string1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{read_line_by_lineRaw(filename = '')}$ does the following:\n",
    "    Open up a file stored in your computed called (filename), and returns its contents as a list. It is intended to be used on data.csv\n",
    "    \n",
    "The last line rawData.pop(0) removes the header. The output is the row that was removed from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read_line_by_lineRaw takes a csv file and returns its rows as a list    \n",
    "def read_line_by_lineRaw(filename = ''):\n",
    "    output = []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            b = line.rstrip('\\n')\n",
    "            a = b.split(',')\n",
    "            output.append(a)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{You need to upload the data.csv file to the jupyter notebook environment for the next cell to work:}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'read_index', 'read_sequence']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rawData is a list of reads, with each row being:\n",
    "#   ['row_count' , 'read_count' , 'read_string']\n",
    "rawData = read_line_by_lineRaw('data.csv')\n",
    "\n",
    "#remove the header row\n",
    "rawData.pop(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " There is a possibility that a particular read X gives a substring of another read Y\n",
    " We eliminate this possibility by doing the following:\n",
    "    \n",
    "1. Compare every possible pair of reads.\n",
    "2. If one of them is a substring of the other, change read to 'x'.\n",
    "3. Write a file ProcessedData.txt with 'x' reads intact.\n",
    "4. Write another file ProcessedData2.txt  with 'x' reads removed.\n",
    "    \n",
    "After manually comparing the number of lines in ProcessedData.txt and ProcessedData2.txt, we realise that\n",
    "None of the reads are sub-reads of another read.\n",
    "So we can use rawData as it is. The code below does the above.\n",
    "Since this is a one-time check, the manual check above is fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(rawData)):\n",
    "    for j in [x for x in range(len(rawData)) if x != i]:\n",
    "        if rawData[i][2] in rawData[j][2]:\n",
    "            rawData[i] = [rawData[i][0] , rawData[i][1] , 'x']\n",
    "\n",
    "with open('ProcessedData.txt' , 'w') as g:\n",
    "    for i in range(len(rawData)):\n",
    "        if rawData[2] != 'x':\n",
    "            g.write(f'{rawData[i][0]},{rawData[i][1]},{rawData[i][2]}\\n')\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "with open('ProcessedData2.txt' , 'w') as g:\n",
    "    for i in range(len(rawData)):\n",
    "        g.write(f'{rawData[i][0]},{rawData[i][1]},{rawData[i][2]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to produce a directed graph with the following as vertices and directed edge labels:\n",
    "1. Vertices are the reads\n",
    "2. Given 2 vertices A and B, the edge from A to B has edge label  -(length of overlap of end of A and beginning of B) \n",
    "\n",
    "$\\textbf{graphEdgeConstructor(m , n , dataset)}$ does the following: \n",
    "Given two reads m and n in a dataset (which should be the list returned by read_line_by_lineRaw(filename = ''), not the original file data.csv), returns a tuple of tuples ((m,n) , (x,y)), where:\n",
    "1. x is the overlap between the end of read m and beginning of read n\n",
    "2. y is the overlap between the end of read n and beginning of read m\n",
    "\n",
    "$\\textbf{contructEdges(dataset)}$ does the following:\n",
    "1. Scan through the entire dataset.\n",
    "2. For pairs of reads (m,n) with non-zero overlaps (x,y) as defined above in graphEdgeConstructor(m , n , dataset), put all of them into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphEdgeConstructor(m , n , dataset):\n",
    "    comparison = SufPreCompare(dataset[m][2] , dataset[n][2])\n",
    "    return ((m,n) , comparison)\n",
    "\n",
    "def constructEdges(dataset):\n",
    "    output = []\n",
    "    test4 = len(dataset)\n",
    "    for i in range(test4):\n",
    "        for j in range(i+1,test4):\n",
    "            temp = graphEdgeConstructor(i , j, dataset)\n",
    "            #if temp[1] != (0,0):\n",
    "            if temp[1][0] > 0 or temp[1][1] > 0:\n",
    "                output.append(temp)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test these functions on the Toy Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0, 1), (4, 0)),\n",
       " ((0, 2), (2, 0)),\n",
       " ((0, 3), (0, 4)),\n",
       " ((1, 2), (3, 0)),\n",
       " ((1, 3), (1, 0)),\n",
       " ((2, 3), (1, 0))]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawData2 = [['0','read_0','TCGATCTG'],['1','read_1','TCTGA'],['2','read_2','TGAGA'],['3','read_3','ATCGA']]\n",
    "rawDataMini = rawData[0:300]\n",
    "#rawDataMini is the first 300 rows of data.csv in list format\n",
    "\n",
    "contructEdges(rawData2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Explanation}:$ We see that the biggest numbers that appear on the right column of tuple are 4, 4, and 3 in rows 0, 2, and 3. This suggests the following 'joining-up' of our DNA sequence:\n",
    "\n",
    "1. row 0: This means there are 4 overlapping letters at the end of read_0 and beginning of read_1\n",
    "2. row 2: This means there are 4 overlapping letters at the end of read_3 and beginning of read_0\n",
    "3. row 3: This means there are 3 overlapping letters at the end of read_1 and beginning of read_2\n",
    "\n",
    "This suggests our DNA should be (read_3) - (read_0) - (read_1) - (read_2). Hence:\n",
    "\n",
    "DNA = 'ATCGATCTGAGA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{constructEdges2(dataset)}$ does the samething as constructEdges(dataset), except that it only returns pairs where the overlap is from 5 to 30 characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructEdges2(dataset):\n",
    "    output = []\n",
    "    test4 = len(dataset)\n",
    "    for i in range(test4):\n",
    "        for j in range(i+1,test4):\n",
    "            temp = graphEdgeConstructor(i , j, dataset)\n",
    "            #if temp[1] != (0,0):\n",
    "            if (temp[1][0] > 4 or temp[1][1] > 4) and temp[1][0]<31 and temp[1][1]<31:\n",
    "                output.append(temp)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create a graph class, and our specific graph is dnaProblem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Graph:\n",
    "    def __init__(self, num_of_nodes, directed=True):\n",
    "        self.m_num_of_nodes = num_of_nodes\n",
    "        self.m_directed = directed\n",
    "\n",
    "        # Initialize the adjacency matrix\n",
    "        # Create a matrix with `num_of_nodes` rows and columns\n",
    "        self.m_adj_matrix = [[0 for column in range(num_of_nodes)] \n",
    "                            for row in range(num_of_nodes)]\n",
    "\n",
    "    def add_edge(self, node1, node2, weight=1):\n",
    "        self.m_adj_matrix[node1][node2] = weight\n",
    "\n",
    "        if not self.m_directed:\n",
    "            self.m_adj_matrix[node2][node1] = weight\n",
    "\n",
    "    def print_adj_matrix(self):\n",
    "        print(self.m_adj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = constructEdges2(rawData)\n",
    "    \n",
    "dnaProblem = Graph(599, directed = True)\n",
    "\n",
    "for i in range(len(edges)):\n",
    "    consider = edges[i]\n",
    "    dnaProblem.add_edge(consider[0][0] , consider[0][1] , weight = -consider[1][0])\n",
    "    dnaProblem.add_edge(consider[0][1] , consider[0][0] , weight = -consider[1][1])\n",
    "    \n",
    "for i in range(len(dnaProblem.m_adj_matrix)):\n",
    "    for j in range(len(dnaProblem.m_adj_matrix)):\n",
    "        if dnaProblem.m_adj_matrix[i][j] > -5:\n",
    "            dnaProblem.m_adj_matrix[i][j] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now plot a bar chart, with horizontal axis being weights and vertical axis being the number of edges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "weights = list(range(-30,-4))\n",
    "finalcounts = []\n",
    "\n",
    "for i in range(-30,-4):\n",
    "    count = 0\n",
    "    for j in range(599):\n",
    "        for k in range(599):\n",
    "            if dnaProblem.m_adj_matrix[j][k] == i:\n",
    "                count = count+1\n",
    "    finalcounts.append(count)\n",
    "    \n",
    "plt.bar(weights,finalcounts)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Task B}$："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
